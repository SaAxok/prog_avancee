# Programmation parall√®le √† m√©moire partag√©e

> **Gravier Kylian INF3-FA**  
> - Rapport mis en forme avec l'aide d'intelligence artificielle (Mistral).  
> - Les TP ont √©t√© r√©alis√©s avec l'aide de GitHub Copilot.  

---

![illustration progammation paratgee](./assets/Illustration_Programmation_Parall√®le.webp)

---

## Table des mati√®res

- [D√©finitions](#d√©finitions)
    - [Thread](#thread)
    - [S√©maphore](#s√©maphore)
    - [Ressource critique](#ressource-critique)
    - [Section critique](#section-critique)
    - [Programmation parall√®le](#programmation-parall√®le)
    - [Programmation partag√©e](#programmation-partag√©e)
    - [Parall√©lisme de t√¢ches](#parall√©lisme-de-t√¢ches)

- [TP1 : Dossier de conception du TP Thread](#tp1--dossier-de-conception-du-tp-thread)
    - [Exercice 1](#exercice-1)
    - [Exercice 2](#exercice-2)

- [TP2 : Affichage synchronis√©](#tp2--affichage-synchronis√©)
    - [S√©maphore](#s√©maphore-1)
        - [Outils de Synchronisation](#outils-de-synchronisation)
        - [Impl√©mentation](#impl√©mentation)
        - [Exemple : Analogie avec un Phare](#exemple--analogie-avec-un-phare)
        - [Proc√©d√©](#proc√©d√©)
        - [Conclusion](#conclusion)

- [TP3 : Bo√Æte aux lettres](#tp3--bo√Æte-aux-lettres)
    - [Analyse et R√©solution](#analyse-et-r√©solution)
    - [Ce que j'ai appris](#ce-que-jai-appris-)
    - [Conclusion](#conclusion)

---

## D√©finitions

### Thread  
Un **thread** est la plus petite unit√© d'ex√©cution dans un programme. Il repr√©sente un flux d'instructions qui peut s'ex√©cuter ind√©pendamment tout en partageant des ressources comme la m√©moire et les fichiers avec d'autres threads du m√™me processus.

---

### S√©maphore  
Un **s√©maphore** est une variable utilis√©e pour g√©rer l'acc√®s concurrent √† une ressource partag√©e. Il peut √™tre binaire (1 ou 0) ou comptant (avec une valeur enti√®re), et ses op√©rations principales sont :  
- **`wait`** : R√©duit la valeur du s√©maphore et bloque si elle devient n√©gative.  
- **`signal`** : Augmente la valeur et r√©veille un thread bloqu√© si n√©cessaire.

---

### Ressource critique  
Une **ressource critique** est un √©l√©ment (m√©moire, fichier, p√©riph√©rique) partag√© entre plusieurs threads ou processus, dont l'acc√®s concurrent peut entra√Æner des incoh√©rences si non contr√¥l√©.

---

### Section critique  
Une **section critique** est une portion du code o√π une ressource critique est acc√©d√©e. Il est essentiel d'assurer qu'une seule entit√© (thread ou processus) l'ex√©cute √† la fois pour √©viter des erreurs ou des incoh√©rences.

---

### Programmation parall√®le  
La **programmation parall√®le** consiste √† ex√©cuter plusieurs t√¢ches en simultan√© sur des processeurs multiples, permettant d'acc√©l√©rer l'ex√©cution d'un programme en divisant les calculs ou t√¢ches.

---

### Programmation partag√©e  
La **programmation partag√©e** implique l'utilisation d'une m√©moire unique accessible par plusieurs threads ou processus. Elle n√©cessite des m√©canismes de synchronisation pour √©viter les conflits.

---

### Parall√©lisme de t√¢ches  
Le **parall√©lisme de t√¢ches** correspond √† l'ex√©cution simultan√©e de t√¢ches diff√©rentes. Contrairement au parall√©lisme de donn√©es, chaque t√¢che effectue une op√©ration distincte et ind√©pendante.

---

## TP1 : Dossier de conception du TP Thread

### Exercice 1

**Impl√©mentation :**  
La classe `UnMobile` repr√©sente un mobile qui se d√©place dans une interface graphique en utilisant un thread. Sa m√©thode `run()` g√®re le mouvement par incr√©ments successifs, suivis de redessins avec `repaint()`.

**Ce que j'ai compris :**  
Le fonctionnement d'un thread inclut :  
- La gestion des boucles d'ex√©cution (dans `run`).  
- L'utilisation de `sleep` pour r√©guler la vitesse.  
- L'importance de redessiner r√©guli√®rement les objets graphiques pour simuler le mouvement.

---

### Exercice 2

**Impl√©mentation :**  
Un mobile est ajout√© √† une fen√™tre avec `add()` dans la classe `UneFenetre`, et un thread est lanc√© pour animer le mobile.

**Ce que j'ai appris :**  
La manipulation de fen√™tres avec `JFrame`, notamment :  
- La gestion de la visibilit√© (`setVisible`).  
- L'ajout de composants dynamiques (comme `UnMobile`).  
- L'utilisation de threads pour animer les composants.

---

## TP2 : Affichage synchronis√©

### S√©maphore  

#### Outils de Synchronisation  
Les s√©maphores sont utilis√©s pour g√©rer l'acc√®s s√©curis√© aux ressources partag√©es. Ils emp√™chent plusieurs threads d'acc√©der simultan√©ment √† une **section critique**, ce qui pourrait entra√Æner des conditions de course.

---

#### Impl√©mentation  

1. **Initialisation** : Choisir la valeur de d√©part en fonction des besoins (1 pour exclusivit√©, >1 pour ressources multiples).  
2. **Interblocages** : Pr√©venir les deadlocks en respectant l'ordre des verrous.  
3. **Performance** : Minimiser les sections critiques pour limiter les d√©lais d'acc√®s.

---

#### Exemple : Analogie avec un Phare  
Le phare r√©gule l'entr√©e des bateaux dans un port.  
- **Vert (1)** : Acc√®s autoris√© √† un bateau.  
- **Rouge (0)** : Attente obligatoire pour les suivants.  
Cela illustre les concepts de `wait` (rouge) et `signal` (vert).

---

#### Proc√©d√©  
Un s√©maphore unique contr√¥le l'acc√®s au deuxi√®me tiers d'une fen√™tre, divis√©e en six sections. Un thread appelle `sem.syncWait()` pour entrer dans la section critique et `sem.syncSignal()` en sortant, assurant qu'un seul mobile y passe √† la fois.

---

### Conclusion  
Les s√©maphores simplifient la synchronisation des threads mais n√©cessitent une impl√©mentation soign√©e pour √©viter les interblocages et pr√©server les performances.

---

## TP3 : Bo√Æte aux lettres

### Analyse et R√©solution

La **BAL (Bo√Æte aux Lettres)** est une file circulaire utilis√©e pour un mod√®le producteur-consommateur. Elle s'appuie sur la classe **`BlockingQueue`** pour synchroniser automatiquement l'acc√®s.  

Dans ce TP, j‚Äôai structur√© la solution autour de la classe **BAL**, qui encapsule l‚Äôinterface **`BlockingQueue`** et simplifie son utilisation. La **BAL** agit comme un point central de communication entre les threads producteurs et consommateurs. Elle masque les d√©tails complexes de synchronisation, en utilisant une instance concr√®te de **`ArrayBlockingQueue`** comme tampon circulaire.  

Cette organisation permet une s√©paration claire des responsabilit√©s : les producteurs et consommateurs interagissent uniquement avec la **BAL** via des m√©thodes d√©di√©es (deposer et retirer), tandis que la gestion des acc√®s concurrents est enti√®rement confi√©e √† l‚Äôimpl√©mentation sous-jacente de la **`BlockingQueue`**. Cette approche favorise la modularit√©, la lisibilit√©, la portabilit√© et la maintenance du code.

---

#### Ce que j'ai appris :  
1. **Gestion simplifi√©e des threads** :  
   Les m√©thodes comme `offer` (ajout) et `poll` (retrait) √©vitent les blocages ind√©finis.  

2. **Arr√™t propre** :  
   Un marqueur sp√©cial signale la fin de la production, permettant aux threads de se terminer correctement.  

3. **Parall√®le avec la boulangerie** :  
   - **D√©p√¥t** : Un boulanger place un pain dans un panier (lettre dans la BAL).  
   - **Retrait** : Un client retire un pain, ou attend si le panier est vide.  
   - **Marqueur de fermeture** : Indique la fin de l'activit√©.

---

### Conclusion  

Ce TP illustre les avantages des outils de synchronisation modernes, comme **`BlockingQueue`**, pour g√©rer efficacement la concurrence, pr√©venir les blocages et simplifier le code.

---

## Partie 3 : 

d√©finitions, fonctionnement et usages : 
- master / worker
- future
- acc√©l√©ration (speedup)
- Scalabilit√©

=> expliquer MonteCarlo
=> expliquer les futures, le role du master worker, comment c'est implementer le parall√©lisme que √ßa offre (M/W montecarlo : g√©n√©ration du point + passage dans la section critique) temps d'exec = ntot/2 + 3/4 wntot
=> work stealing pool
=> explication de application de l'api concurrent 
=> Si c'est bien programm√©  : montecarlo doit avoir une bonne scalabilit√© forte et faible. Mais √† cause du num√©rique c'est vite limit√©
=> Montecralo, analyse des performmances 

--- 

## Partie 4

=> Programmation distribu√©e
=> Master envoie des msg aux workers : workers sont parrall√®les et renvoie le result au master
- paratg√©e : passage d'argument, r√©cup√©ration du result avec `.get()`
- worker ailleurs physiquement implique d'envoyer des msg r√©seaux, et recevoir result en r√©seau (socket)  

**Diff : communnication par msg r√©seaux et non en partage d'arguments** 

=> Comment impl√©menter M / W en distribu√©e ?
- Utilisation de socket client / server qu'on utilise en tant que M/W
    - Client : Master
    - Server : Worker
- Faire un cours de socket dans le rapport

## Analyse des Sockets JAVA

!["Image UML WorkerSocket"](./assets/Socket%20rapport%20TP.jpg)

### Analyse MasterSocket.java

#### √âtapes principales dans le code
**Initialisation des workers** :
- Le master demande combien de workers (processus) seront utilis√©s. Il ouvre un socket (canal de communication) pour chaque worker sur un port donn√©.
**Envoi des t√¢ches aux workers** :
- Chaque worker re√ßoit le nombre total de points √† g√©n√©rer pour l'estimation de ùúã.

**Traitement par les workers** :
- Les workers g√©n√®rent des points al√©atoires dans un carr√©, comptent ceux qui tombent dans un quart de cercle et renvoient leurs r√©sultats au master.

**R√©cup√©ration des r√©sultats** :
- Le master collecte les r√©sultats des workers via leurs sockets respectifs.
- Il combine ces r√©sultats pour calculer la valeur approximative de ùúã.

**Affichage des r√©sultats** :
- Le master affiche ùúã, l'erreur relative, et les statistiques de performance (dur√©e, nombre de points, etc.).
- L'utilisateur peut choisir de r√©p√©ter la simulation.

**Fermeture des sockets** :
- Une fois la simulation termin√©e, les sockets entre le master et les workers sont ferm√©s proprement.

#### Sockets : 
- **Socket c√¥t√© master** : Utilis√© pour envoyer des t√¢ches et recevoir des r√©sultats.
- **Socket c√¥t√© worker (non montr√© ici)** : √âcoute les messages du master, ex√©cute la t√¢che, puis renvoie le r√©sultat.

#### Flux g√©n√©ral de la communication
**Master :**
- Connecte un socket pour chaque worker.
- Envoie une t√¢che √† chaque worker via un flux d'√©criture (PrintWriter).
- Lit les r√©sultats des workers via un flux de lecture (BufferedReader).

**Workers (c√¥t√© serveur, non montr√© ici) :**
- √âcoute sur un port sp√©cifique.
- Re√ßoit les donn√©es envoy√©es par le master.
- Effectue le calcul et renvoie le r√©sultat.

### Analyse WorkerSocket.java

#### √âtapes principales du code Worker
**Configuration du Worker :**
- Le Worker d√©marre un serveur socket sur un port donn√© (par d√©faut 25545 ou sp√©cifi√© en argument).
- Il attend une connexion entrante du Master via le socket.

**Communication avec le Master :**
- Une fois connect√©, le Worker √©coute les messages du Master en utilisant un flux d'entr√©e (BufferedReader).
- Apr√®s avoir re√ßu les donn√©es, il effectue le calcul n√©cessaire.

**Envoi des r√©sultats au Master :**
- Le Worker utilise un flux de sortie (PrintWriter) pour renvoyer les r√©sultats du calcul au Master.

**Gestion des messages et fin de t√¢che :**
- Si le message re√ßu est "END", le Worker arr√™te son ex√©cution.
Sinon, il continue √† traiter les donn√©es envoy√©es par le Master.

#### Flux de communication entre Master et Worker
**C√¥t√© Master :**
- **Client socket :** Le Master initie la connexion et envoie des t√¢ches aux Workers. Le Master attend les r√©ponses des Workers pour agr√©ger les r√©sultats.

**C√¥t√© Worker :**
- **Serveur socket :** Le Worker accepte les connexions du Master. Chaque message re√ßu est interpr√©t√© comme une instruction (par exemple, combien de points g√©n√©rer pour la m√©thode Monte Carlo). Une fois le calcul termin√©, le r√©sultat est renvoy√© au Master.

## MonteCarlo Master/Worker Socket

=> expliquer les changements apport√©s pour calculer PI et √©tablir les communnications M/W